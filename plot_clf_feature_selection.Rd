% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ranger_clf_plot.R
\name{plot_clf_feature_selection}
\alias{plot_clf_feature_selection}
\title{plot_clf_feature_selection}
\usage{
plot_clf_feature_selection(
  x,
  y,
  nfolds = 5,
  rf_clf_model,
  metric = "AUROC",
  positive_class = NA,
  outdir = NULL
)
}
\arguments{
\item{x}{The data frame or data matrix for model training.}

\item{y}{A factor related to the responsive vector for training data.}

\item{nfolds}{The number of folds in the cross-validation for each feature set.}

\item{rf_clf_model}{The rf classification model from \code{rf.out.of.bag}}

\item{metric}{The classification performance metric applied.
If binary classification, this must be one of "AUROC", "Accuracy", "Kappa", "F1".
If multi-class classification, this must be one of "Accuracy", "Kappa".}

\item{positive_class}{A class of the y.}

\item{outdir}{The output directory.}
}
\description{
Plot the classification performance against the gradually reduced number of features used in the modeling.
}
\examples{
set.seed(123)
require("gtools")
n_features <- 100
prob_vec <- rdirichlet(5, sample(n_features))
x <- data.frame(rbind(t(rmultinom(7, 7*n_features, prob_vec[1, ])),
            t(rmultinom(8, 8*n_features, prob_vec[2, ])),
            t(rmultinom(15, 15*n_features, prob_vec[3, ])),
            t(rmultinom(15, 15*n_features, prob_vec[4, ])),
            t(rmultinom(15, 15*n_features, prob_vec[5, ]))))
y<-factor(c(rep("A", 30), rep("C", 30)))
s<-factor(rep(c("B1", "B2", "B3", "B4"), 15))
rf_model<-rf.cross.validation(x, y, nfolds=5)
summ <- plot_clf_feature_selection(x, y, nfolds=5, rf_model, metric="AUROC", outdir=NULL)
summ <- plot_clf_feature_selection(x, y, nfolds=s, rf_model, metric="AUROC", outdir=NULL)
res<-replicate(10, plot_clf_feature_selection(x, y,
nfolds=5, rf_model, metric="AUROC", outdir=NULL))
do.call(rbind, res["top_n_perf", ])
}
\author{
Shi Huang
}
