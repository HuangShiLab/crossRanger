% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ranger_RF_util.R
\name{rf.cross.validation}
\alias{rf.cross.validation}
\title{rf.cross.validation}
\usage{
rf.cross.validation(
  x,
  y,
  nfolds = 3,
  ntree = 500,
  verbose = FALSE,
  sparse = FALSE,
  imp_pvalues = FALSE,
  ...
)
}
\arguments{
\item{x}{Training data: data.matrix or data.frame.}

\item{y}{A response vector. If a factor, classification is assumed, otherwise regression is assumed.}

\item{nfolds}{The number of folds in the cross validation. If nfolds > length(y)
or nfolds==-1, uses leave-one-out cross-validation. If nfolds was a factor, it means customized folds (e.g., leave-one-group-out cv) were set for CV.}

\item{ntree}{The number of trees.}

\item{verbose}{A boolean value indicates if showing computation status and estimated runtime.}

\item{sparse}{A boolean value indicates if the input matrix transformed into sparse matrix for rf modeling.}

\item{imp_pvalues}{If compute both importance score and pvalue for each feature.}

\item{...}{Other parameters applicable to `ranger`.}
}
\value{
Object of class \code{rf.cross.validation} with elements including a \code{ranger} object and mutiple metrics for model evaluations.
}
\description{
It runs standard random forests with n-folds cross-validation error estimation for both classification and regression using rf.out.of.bag.
}
\examples{

x0 <- data.frame(t(rmultinom(16,160,c(.001,.5,.3,.3,.299))) + 0.65)
x <- data.frame(rbind(t(rmultinom(7, 75, c(.201,.5,.02,.18,.099))),
            t(rmultinom(8, 75, c(.201,.4,.12,.18,.099))),
            t(rmultinom(15, 75, c(.011,.3,.22,.18,.289))),
            t(rmultinom(15, 75, c(.091,.2,.32,.18,.209))),
            t(rmultinom(15, 75, c(.001,.1,.42,.18,.299)))))
s<-factor(c(rep("A", 15), rep("B", 15), rep("C", 15), rep("D", 15)))
y<-factor(rep(c("Y", "N"), 30))
y0<-factor(c(rep("A", 10), rep("B", 30), rep("C", 5), rep("D", 15)))
system.time(rf.cross.validation(x, y, imp_pvalues=FALSE))
system.time(rf.cross.validation(x, y, imp_pvalues=TRUE))
rf.cross.validation(x, y0, imp_pvalues=FALSE)
y_n<- 1:60
rf.cross.validation(x, y_n, nfolds=5, imp_pvalues=FALSE)
rf.cross.validation(x, y_n, nfolds=5, imp_pvalues=TRUE)
# when nfolds is a factor, it actually run a leave-one-group-out cv
rf.cross.validation(x, y, nfolds=s, imp_pvalues=TRUE)
rf.cross.validation(x, y_n, nfolds=s, imp_pvalues=FALSE)
}
\seealso{
ranger
}
\author{
Shi Huang
}
